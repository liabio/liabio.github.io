<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>kubernetes on 小碗汤的博客</title>
    <link>https://liabio.github.io/categories/kubernetes/</link>
    <description>Recent content in kubernetes on 小碗汤的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 10 Oct 2019 17:20:28 +0800</lastBuildDate>
    
	<atom:link href="https://liabio.github.io/categories/kubernetes/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>如何批量删除k8s资源对象</title>
      <link>https://liabio.github.io/posts/2019-10-10-%E6%89%B9%E9%87%8F%E5%88%A0%E9%99%A4k8s-pvc-pv/</link>
      <pubDate>Thu, 10 Oct 2019 17:20:28 +0800</pubDate>
      
      <guid>https://liabio.github.io/posts/2019-10-10-%E6%89%B9%E9%87%8F%E5%88%A0%E9%99%A4k8s-pvc-pv/</guid>
      <description>在云平台开发、中间件容器化时，经常会遇到批量删除k8s资源对象的需求，下面记录一下kubectl和golang发送删除pvc、pv、pod请求的例子，便于后续学习查阅 kubectl发送删除请求 根据label批量删除pod： kubectl delete pod -n kube-system -l &amp;quot;harmonycloud.cn/statefulset=redis-ll-1010-a&amp;quot; 根据</description>
    </item>
    
    <item>
      <title>kubernetes自定义资源对象高级功能</title>
      <link>https://liabio.github.io/posts/2019-09-30-kubernetes%E8%87%AA%E5%AE%9A%E4%B9%89%E8%B5%84%E6%BA%90%E5%AF%B9%E8%B1%A1%E9%AB%98%E7%BA%A7%E5%8A%9F%E8%83%BD/</link>
      <pubDate>Mon, 30 Sep 2019 14:41:33 +0800</pubDate>
      
      <guid>https://liabio.github.io/posts/2019-09-30-kubernetes%E8%87%AA%E5%AE%9A%E4%B9%89%E8%B5%84%E6%BA%90%E5%AF%B9%E8%B1%A1%E9%AB%98%E7%BA%A7%E5%8A%9F%E8%83%BD/</guid>
      <description>kubernetes自定义资源对象再极大程度提高了API Server的可扩展性，让企业能够根据业务需求通过CRD编写controller或者operator来实现生产中各种特殊场景。随着k8s的版本升级，CRD的功能也越来越完善，下面对其中</description>
    </item>
    
    <item>
      <title>k8s中部署负载均衡器ingress-nginx</title>
      <link>https://liabio.github.io/posts/2019-09-24-k8s%E4%B8%AD%E9%83%A8%E7%BD%B2ingress-nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8/</link>
      <pubDate>Tue, 24 Sep 2019 09:59:46 +0800</pubDate>
      
      <guid>https://liabio.github.io/posts/2019-09-24-k8s%E4%B8%AD%E9%83%A8%E7%BD%B2ingress-nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8/</guid>
      <description>正文 在Kubernetes中，服务和Pod的IP地址仅可以在集群网络内部使用，对于集群外的应用是不可见的。为了使外部的应用能够访问集群内的服务，在Kubernetes 目前 提供了以下几种方案： NodePort LoadBalancer Ingress 本节主要就ingress和ingress控制</description>
    </item>
    
    <item>
      <title>k8s使用Job执行任务失败了怎么办</title>
      <link>https://liabio.github.io/posts/2019-09-24-k8s%E4%BD%BF%E7%94%A8Job%E6%89%A7%E8%A1%8C%E4%BB%BB%E5%8A%A1%E5%A4%B1%E8%B4%A5%E4%BA%86%E6%80%8E%E4%B9%88%E5%8A%9E/</link>
      <pubDate>Tue, 24 Sep 2019 09:59:46 +0800</pubDate>
      
      <guid>https://liabio.github.io/posts/2019-09-24-k8s%E4%BD%BF%E7%94%A8Job%E6%89%A7%E8%A1%8C%E4%BB%BB%E5%8A%A1%E5%A4%B1%E8%B4%A5%E4%BA%86%E6%80%8E%E4%B9%88%E5%8A%9E/</guid>
      <description>正文 Kubernetes 中使用 Job 和 CronJob 两个资源分别提供了一次性任务和定时任务的特性，这两种对象也使用控制器模型来实现资源的管理，我们在这篇文章来介绍Job执行如果失败了会怎么样呢？ 修改job-fail.yaml，故意引入一个错误： Never 如果将 restartPolicy 设置为 Never 会怎么样？下</description>
    </item>
    
    <item>
      <title>kubernetes垃圾回收器GarbageCollector Controller源码分析（一）</title>
      <link>https://liabio.github.io/posts/2019-09-24-kubernetes%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8GarbageCollectorController%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%901/</link>
      <pubDate>Tue, 24 Sep 2019 09:59:46 +0800</pubDate>
      
      <guid>https://liabio.github.io/posts/2019-09-24-kubernetes%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8GarbageCollectorController%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%901/</guid>
      <description>kubernetes版本：1.13.2 背景 由于operator创建的redis集群，在kubernetes apiserver重启后，redis集群被异常删除（包括redis exporter statefulset、redis statefulset）。删除后</description>
    </item>
    
    <item>
      <title>采坑指南——k8s域名解析coredns问题排查过程</title>
      <link>https://liabio.github.io/posts/2019-09-24-%E9%87%87%E5%9D%91%E6%8C%87%E5%8D%97-k8s%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90coredns%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E8%BF%87%E7%A8%8B/</link>
      <pubDate>Tue, 24 Sep 2019 09:59:46 +0800</pubDate>
      
      <guid>https://liabio.github.io/posts/2019-09-24-%E9%87%87%E5%9D%91%E6%8C%87%E5%8D%97-k8s%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90coredns%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E8%BF%87%E7%A8%8B/</guid>
      <description>正文 前几天，在ucloud上搭建的k8s集群（搭建教程后续会发出）。今天发现域名解析不了。 组件版本：k8s 1.15.0，coredns：1.3.1 过程是这样的： 首先用以下yaml文件创建了一个nginx服务 apiVersion: v1 kind: Service metadata: name: nginx-svc-old labels: app: nginx-svc spec: selector: app: nginx ports: - protocol:</description>
    </item>
    
    <item>
      <title>手把手教你搭建kubernetes集群</title>
      <link>https://liabio.github.io/posts/2019-05-14-%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E6%90%AD%E5%BB%BAkubernetes%E9%9B%86%E7%BE%A4/</link>
      <pubDate>Tue, 14 May 2019 09:59:46 +0800</pubDate>
      
      <guid>https://liabio.github.io/posts/2019-05-14-%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E6%90%AD%E5%BB%BAkubernetes%E9%9B%86%E7%BE%A4/</guid>
      <description>cat &amp;gt; /etc/yum.repos.d/kubernetes.repo &amp;lt;&amp;lt; EOF [kubernetes] name=Kubernetes baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=0 repo_gpgcheck=1 gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF 安装kubeadm、kubectl、kubelet yum install -y kubeadm kubelet kubectl 如果在云服务器上搭建时，IP-18.219.28.143是公网IP kubeadm init --kubernetes-version=v1.14.1 --pod-network-cidr=10.244.0.0/16 --service-cidr=10.96.0.0/12 --apiserver-advertise-address=18.219.28.143 --ignore-preflight-errors=Swap,NumCPU init的时候可能会： [kubelet-check] Initial timeout of 40s passed ![](/img/build-kubernetes-cluster-learning/install_kubernetes_cluster2.png) 需要把/etc/kubernete</description>
    </item>
    
    <item>
      <title>手把手教你搭建kubernetes集群1</title>
      <link>https://liabio.github.io/posts/2019-05-14-%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E6%90%AD%E5%BB%BAkubernetes%E9%9B%86%E7%BE%A41/</link>
      <pubDate>Tue, 14 May 2019 09:59:46 +0800</pubDate>
      
      <guid>https://liabio.github.io/posts/2019-05-14-%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E6%90%AD%E5%BB%BAkubernetes%E9%9B%86%E7%BE%A41/</guid>
      <description>部署 以CentOS7为基础，搭建一个Master主机和三个Node主机，各个Node主机的配置方式基本相同。 OS: CentOS 7.5 x86_64 Container runtime: Docker 18.06.ce Kubernetes: 1.13 IP 地址 主机名 角色 192.168.50.71 master, master.kubernetes.io master 192.168.50.72 node01, node01.kubernetes.io node 192.168.50.73 node02, node02.kubernetes.io node 192.168.50.74 node03, node03.kubernetes.io node 这里需要使用常规的域名格式，因为后面需要为集群配置Kuberne</description>
    </item>
    
    <item>
      <title>搭建k8s环境时gcr.io和quay.io拉取镜像失败</title>
      <link>https://liabio.github.io/posts/2019-05-14-%E6%90%AD%E5%BB%BAk8s%E7%8E%AF%E5%A2%83%E6%97%B6gcr.io%E5%92%8Cquay.io%E6%8B%89%E5%8F%96%E9%95%9C%E5%83%8F%E5%A4%B1%E8%B4%A5/</link>
      <pubDate>Tue, 14 May 2019 09:59:46 +0800</pubDate>
      
      <guid>https://liabio.github.io/posts/2019-05-14-%E6%90%AD%E5%BB%BAk8s%E7%8E%AF%E5%A2%83%E6%97%B6gcr.io%E5%92%8Cquay.io%E6%8B%89%E5%8F%96%E9%95%9C%E5%83%8F%E5%A4%B1%E8%B4%A5/</guid>
      <description>k8s在使用编排（manifest）工具进行yaml文件启动pod时，会遇到官方所给例子中spec.containers.image包含： quay.io/coreos/example_ gcr.io/google_containers/example_ 也就是说，从quay.io和gcr.io进行镜像拉取，我们知道，国内访问外网是被屏蔽了的。可以将其</description>
    </item>
    
    <item>
      <title>Pod调度到集群中某node节点失败</title>
      <link>https://liabio.github.io/posts/2018-12-13-pod%E8%B0%83%E5%BA%A6%E5%88%B0%E9%9B%86%E7%BE%A4%E4%B8%AD%E6%9F%90node%E8%8A%82%E7%82%B9%E5%A4%B1%E8%B4%A5/</link>
      <pubDate>Thu, 13 Dec 2018 16:43:35 +0800</pubDate>
      
      <guid>https://liabio.github.io/posts/2018-12-13-pod%E8%B0%83%E5%BA%A6%E5%88%B0%E9%9B%86%E7%BE%A4%E4%B8%AD%E6%9F%90node%E8%8A%82%E7%82%B9%E5%A4%B1%E8%B4%A5/</guid>
      <description>Fixing rpc.statd is not running but is required for remote locking If you come across this error while attempting to mount an NFS filesystem it means that the statd process is not running. mount -a -t nfs mount.nfs: rpc.statd is not running but is required for remote locking. mount.nfs: Either use &#39;-o nolock&#39; to keep locks local, or start statd. mount.nfs: an incorrect mount option was specified Here’s how to fix the rpc.statd is not running error on el6 First, ensure that rpcbind is running and that it is set to start on boot /etc/init.d/rpcbind start Starting rpcbind: [ OK ] chkconfig rpcbind on Then, start the nfslock service /etc/init.d/nfslock start Starting NFS statd: [</description>
    </item>
    
    <item>
      <title>搭建k8s集群遇到的问题</title>
      <link>https://liabio.github.io/posts/2018-11-14-%E6%90%AD%E5%BB%BAk8s%E9%9B%86%E7%BE%A4%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/</link>
      <pubDate>Wed, 14 Nov 2018 16:57:38 +0800</pubDate>
      
      <guid>https://liabio.github.io/posts/2018-11-14-%E6%90%AD%E5%BB%BAk8s%E9%9B%86%E7%BE%A4%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/</guid>
      <description>部署CalicoNode（所有节点）报错： Oct 10 21:04:55 smallsoup docker[76907]: bird: BGP: Unexpected connect from unknown address 192.168.1.104 (port 58153) Oct 10 21:04:59 smallsoup docker[76907]: bird: BGP: Unexpected connect from unknown address 192.168.1.104 (port 40415) Oct 10 21:05:00 smallsoup docker[76907]: 2018-10-10 13:05:00.213 [INFO][87] int_dataplane.go 690: Applying dataplane updates Oct 10 21:05:00 smallsoup docker[76907]: 2018-10-10 13:05:00.213 [INFO][87] ipsets.go 224: Asked to resync with the dataplane on next update. family=&amp;quot;inet&amp;quot; Oct 10 21:05:00 smallsoup docker[76907]: 2018-10-10 13:05:00.213 [INFO][87] ipsets.go 255: Resyncing ipsets with dataplane. family=&amp;quot;inet&amp;quot; Oct 10 21:05:00 smallsoup docker[76907]: 2018-10-10 13:05:00.218 [INFO][87] ipsets.go 297: Finished resync family=&amp;quot;inet&amp;quot; numInconsistenciesFound=0 resyncDuration=4.542824ms Oct 10 21:05:00 smallsoup docker[76907]: 2018-10-10</description>
    </item>
    
    <item>
      <title>kubernetes自定义资源类型代码自动生成</title>
      <link>https://liabio.github.io/posts/2018-11-02-k8s%E8%87%AA%E5%AE%9A%E4%B9%89%E8%B5%84%E6%BA%90%E7%B1%BB%E5%9E%8B%E4%BB%A3%E7%A0%81%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90/</link>
      <pubDate>Fri, 02 Nov 2018 15:14:14 +0800</pubDate>
      
      <guid>https://liabio.github.io/posts/2018-11-02-k8s%E8%87%AA%E5%AE%9A%E4%B9%89%E8%B5%84%E6%BA%90%E7%B1%BB%E5%9E%8B%E4%BB%A3%E7%A0%81%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90/</guid>
      <description>用以下命令生成代码： ./generate-groups.sh all &amp;quot;github.com/openshift-evangelist/crd-code-generation/pkg/client&amp;quot; &amp;quot;github.com/openshift-evangelist/crd-code-generation/pkg/apis&amp;quot; &amp;quot;ingressgroup:v1&amp;quot; 第一个报错 生成代码报错： Generating deepcopy funcs F0910 19:18:35.552948 12153 main.go:82] Error: Failed making a parser: unable to add directory &amp;quot;github.com/openshift-evangelist/crd-code-generation/pkg/client&amp;quot;: unable to import &amp;quot;github.com/asdfsx/getkubeconfig/pkg/apis/example/v1&amp;quot;: cannot find package &amp;quot;github.com/openshift-evangelist/crd-code-generation/pkg/client&amp;quot; in any of: D:/Program Files/Go/go103/src/github.com/openshift-evangelist/crd-code-generation/pkg/client (from $GOROOT) D:/SoftwareAndProgram/program/Go/Development/src/github.com/openshift-evangelist/crd-code-generation/pkg/client (from $GOPATH) 这个问题可以参考issue 可以参考这个文章： https://medium.com/@trstringer/create-kubernetes-controllers-for-core-and-custom-resources-62fc35ad64a3 由于该链接国内访问比较困难，故转载到了这里： https://www.jianshu.com/p/dcfe6eac4152 第二个报错： Generating deepcopy funcs F1104 02:57:44.419529 35</description>
    </item>
    
    <item>
      <title>Kubernetes Pod Exec接口调用</title>
      <link>https://liabio.github.io/posts/2018-10-02-kubernetesPodExec%E6%8E%A5%E5%8F%A3%E8%B0%83%E7%94%A8/</link>
      <pubDate>Tue, 02 Oct 2018 15:12:59 +0800</pubDate>
      
      <guid>https://liabio.github.io/posts/2018-10-02-kubernetesPodExec%E6%8E%A5%E5%8F%A3%E8%B0%83%E7%94%A8/</guid>
      <description>一般生产环境上由于网络安全策略，大多数端口是不能为集群外部访问的。多个集群之间一般都是通过k8s的ApiServer组件提供的接口通信，如https://192.168.1.101:6443。所以在做云平台时，集群管理平台（雅称：观云台）需</description>
    </item>
    
    <item>
      <title>Extending Kubernetes: Create Controllers For Core And Custom Resources</title>
      <link>https://liabio.github.io/posts/2018-06-02-ExtendingKubernetes-CreateControllersForCoreAndCustomResources/</link>
      <pubDate>Sat, 02 Jun 2018 15:04:35 +0800</pubDate>
      
      <guid>https://liabio.github.io/posts/2018-06-02-ExtendingKubernetes-CreateControllersForCoreAndCustomResources/</guid>
      <description>原文地址：https://medium.com/@trstringer/create-kubernetes-controllers-for-core-and-custom-resources-62fc35ad64a3 感谢原作者的输出。由于原</description>
    </item>
    
    <item>
      <title>开发一个operator扩展kubernetes的能力</title>
      <link>https://liabio.github.io/posts/2018-05-02-%E5%BC%80%E5%8F%91%E4%B8%80%E4%B8%AAoperator%E6%89%A9%E5%B1%95kubernetes%E7%9A%84%E8%83%BD%E5%8A%9B/</link>
      <pubDate>Wed, 02 May 2018 15:01:15 +0800</pubDate>
      
      <guid>https://liabio.github.io/posts/2018-05-02-%E5%BC%80%E5%8F%91%E4%B8%80%E4%B8%AAoperator%E6%89%A9%E5%B1%95kubernetes%E7%9A%84%E8%83%BD%E5%8A%9B/</guid>
      <description>Operator 是 CoreOS 推出的旨在简化复杂有状态应用管理，它是一个感知应用状态的控制器，通过扩展 Kubernetes API 来自动创建、管理和配置应用实例。 Operator 基于 CRD 扩展资源对象，并通过控制器来保证应用处于预期状态。 通过 Kubernetes API 观察集群的当前状态； 分析当前状态与期望状态的差别； 调用k8s</description>
    </item>
    
    <item>
      <title>史上最全k8s必学必会知识梳理</title>
      <link>https://liabio.github.io/posts/2018-03-11-%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8k8s%E5%BF%85%E5%AD%A6%E5%BF%85%E4%BC%9A%E7%9F%A5%E8%AF%86%E6%A2%B3%E7%90%86/</link>
      <pubDate>Sun, 11 Mar 2018 14:56:02 +0800</pubDate>
      
      <guid>https://liabio.github.io/posts/2018-03-11-%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8k8s%E5%BF%85%E5%AD%A6%E5%BF%85%E4%BC%9A%E7%9F%A5%E8%AF%86%E6%A2%B3%E7%90%86/</guid>
      <description>正文 kube-apiserver 对外暴露了Kubernetes API。它是的 Kubernetes 核心控制层。它被设计为水平扩展，即通过部署更多实例来横向扩展。API Server 负责和 etcd 交互（其他组件不会直接操作 etcd，只有 API Server 这么做），是整个 kubernetes 集群的数据中心，所有的交互都是以 API Server 为核心的。A</description>
    </item>
    
  </channel>
</rss>